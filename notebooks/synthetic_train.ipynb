{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training With Synthetic Patterns\n",
    "\n",
    "by Victor Hugo Flores Muñoz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "from zernike import RZern\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza(A):\n",
    "    mask = np.isnan(A)\n",
    "    B = np.nan_to_num(A, nan=0)\n",
    "    C = (B - B.min())/(B.max() - B.min()) * 2 - 1\n",
    "    C[mask] = 0.0\n",
    "    return C\n",
    "\n",
    "def normaliza_pos(A):\n",
    "    mask = np.isnan(A)\n",
    "    B = np.nan_to_num(A, nan=0)\n",
    "    C = (B - B.min())/(B.max() - B.min())\n",
    "    C[mask] = 0.0\n",
    "    return C\n",
    "\n",
    "def generate_mask(reference):\n",
    "    mask = np.isnan(reference)\n",
    "    mask = np.logical_not(mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants and parameters for the zernike generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "cart = RZern(2)\n",
    "ddx = np.linspace(-1.0, 1.0, WIDTH)\n",
    "ddy = np.linspace(-1.0, 1.0, HEIGHT)\n",
    "xv, yv = np.meshgrid(ddx, ddy)\n",
    "cart.make_cart_grid(xv, yv)\n",
    "num_coef = cart.nk\n",
    "print(\"Number of coefficients \", num_coef)\n",
    "Phi = cart.eval_grid(np.array([0,1,0,0,0,0]), matrix=True)\n",
    "MASK = generate_mask(Phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneradorZ(num_samples=50000, num_coef=10, h=256, w=256):\n",
    "    y = np.empty((num_samples, num_coef))\n",
    "    X = np.empty((num_samples, h, w))\n",
    "    Xcos = np.empty((num_samples, h, w))\n",
    "    for k in range(num_samples):\n",
    "        y[k] = [\n",
    "            random.random() * 20 - 10,\n",
    "            random.random() * 30 - 15,\n",
    "            random.random() * 30 - 15,\n",
    "            random.random() * 30 - 15,\n",
    "            random.random() * 30 - 15,\n",
    "            random.random() * 30 - 15\n",
    "        ]\n",
    "        Phi = cart.eval_grid(y[k], matrix=True)\n",
    "        X[k,:,:] = normaliza_pos(Phi)\n",
    "        Xcos[k,:,:] = normaliza_pos(np.cos(Phi))\n",
    "    return X, y, Xcos\n",
    "\n",
    "def GeneradorZ_sparse(num_samples=50000, num_coef=10, h=256, w=256):\n",
    "    y = np.empty((num_samples,num_coef))\n",
    "    X = np.empty((num_samples, h, w))\n",
    "    Xcos = np.empty((num_samples, h, w))\n",
    "    for k in range(num_samples):\n",
    "        y[k] = np.zeros(num_coef)\n",
    "        n_terms = np.random.randint(1,num_coef)\n",
    "        for cont in range(n_terms):\n",
    "            index = np.random.randint(num_coef)\n",
    "            if index == 0:\n",
    "                y[k, index] = random.random() * 20 - 10\n",
    "            else:\n",
    "                y[k, index] = random.random() * 30 - 15\n",
    "        Phi = cart.eval_grid(y[k], matrix=True)\n",
    "        X[k,:,:] = normaliza_pos(Phi)\n",
    "        Xcos[k,:,:] = normaliza_pos(np.cos(Phi))\n",
    "    return X, y, Xcos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the dataset with 10000 samples:\n",
    "\n",
    "`X` are the phases\n",
    "\n",
    "`y` are the coefficients\n",
    "\n",
    "`Xcos` are the cosine function of the phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 10000\n",
    "\n",
    "X1, y1, Xcos1 = GeneradorZ(num_samples=NUM_SAMPLES//2, \n",
    "                           num_coef=num_coef, \n",
    "                           h=HEIGHT, \n",
    "                           w=WIDTH)\n",
    "X2, y2, Xcos2 = GeneradorZ_sparse(num_samples=NUM_SAMPLES//2, \n",
    "                                  num_coef=num_coef, \n",
    "                                  h=HEIGHT, \n",
    "                                  w=WIDTH)\n",
    "X = np.concatenate((X1, X2))\n",
    "y = np.concatenate((y1, y2))\n",
    "Xcos = np.concatenate((Xcos1, Xcos2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_train = round(NUM_SAMPLES * .9)\n",
    "X, y, Xcos= shuffle(X, y, Xcos)\n",
    "X_train = np.expand_dims(X[:num_samples_train], axis=3)\n",
    "X_train_cos = np.expand_dims(Xcos[:num_samples_train], axis=3)\n",
    "y_train = y[:num_samples_train]\n",
    "X_test = np.expand_dims(X[num_samples_train:], axis=3)\n",
    "X_test_cos = np.expand_dims(Xcos[num_samples_train:], axis=3)\n",
    "y_test = y[num_samples_train:]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_cos, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_cos, y_test))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "validation_split = 0.1\n",
    "num_samples = len(train_dataset)\n",
    "num_train = round(num_samples * (1 - validation_split))\n",
    "train_ds = train_dataset.take(num_train).batch(BATCH_SIZE)\n",
    "val_dataset = train_dataset.skip(num_train).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 1\n",
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0.0, 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters,\n",
    "            size,\n",
    "            padding='same',\n",
    "            kernel_initializer=initializer\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters,\n",
    "            4,\n",
    "            strides=2,\n",
    "            padding='same',\n",
    "            kernel_initializer=initializer,\n",
    "            use_bias=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0.0, 0.02)\n",
    "    \n",
    "    result = tf.keras.Sequential()\n",
    "    \n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters,\n",
    "            4,\n",
    "            strides=2,\n",
    "            padding='same',\n",
    "            kernel_initializer=initializer,\n",
    "            use_bias=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(\n",
    "            filters,\n",
    "            size,\n",
    "            padding='same',\n",
    "            kernel_initializer=initializer\n",
    "        )\n",
    "    )\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "        \n",
    "    return result\n",
    "\n",
    "def Encoder(attention=False):\n",
    "    inputs = tf.keras.layers.Input(shape=[256, 256, 1])\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(16, 3), # (bs, 128, 128, 16)\n",
    "        downsample(32, 3), # (bs, 64, 64, 32)\n",
    "        downsample(64, 3), # (bs, 32, 32, 64)\n",
    "        downsample(128, 3), # (bs, 16, 16, 128)Max-Pool\n",
    "        downsample(256, 3), # (bs, 8, 8, 256)\n",
    "        downsample(256, 3), # (bs, 4, 4, 256)\n",
    "        downsample(512, 3), # (bs, 2, 2, 512)\n",
    "    ]\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        [height, width, chan] = x.shape[1:]\n",
    "        if attention:\n",
    "            # Attention to layers 32 to 8\n",
    "            if height <= 32 and height >= 8:\n",
    "                x = tf.reshape(x, [-1, height*width, chan])\n",
    "                x = tf.keras.layers.Attention()([x, x])\n",
    "                x = tf.reshape(x, [-1, height, width, chan])\n",
    "    latent_space_dim = (x.shape)[1:]\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name='encoder'), latent_space_dim\n",
    "\n",
    "def Decoder(latent_space_dim):\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(np.prod(latent_space_dim),))\n",
    "    inputs_reshaped = tf.keras.layers.Reshape(target_shape=(latent_space_dim))(inputs)\n",
    "\n",
    "    up_stack =[ \n",
    "        upsample(512, 3), # (bs, 4, 4, 256)\n",
    "        upsample(256, 3), # (bs, 8, 8, 256)\n",
    "        upsample(256, 3), # (bs, 16, 16, 128)\n",
    "        upsample(128, 3), # (bs, 32, 32, 64)\n",
    "        upsample(64, 3), # (bs, 64, 64, 32)\n",
    "        upsample(32, 3), # (bs, 128, 128, 16)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0.0, 0.02)\n",
    "\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "        OUTPUT_CHANNELS,\n",
    "        kernel_size=4,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer=initializer,\n",
    "        activation='relu'\n",
    "    )\n",
    "\n",
    "    x = inputs_reshaped\n",
    "\n",
    "    for up in up_stack:\n",
    "        x = up(x)\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name='decoder')\n",
    "\n",
    "encoder, latent_space_dim = Encoder(attention=False)\n",
    "decoder = Decoder(latent_space_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Loss Function of the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "LAMBDA = 100\n",
    "\n",
    "def ae_loss(y_true, y_pred):\n",
    "    return LAMBDA * loss_object(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dense Neural Network\n",
    "\n",
    "To estimate the Zernike coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_decoder(latent_space_dim):\n",
    "\n",
    "    dense_input = tf.keras.layers.Input(shape=(np.prod(latent_space_dim),), name=\"dense_input\")\n",
    "\n",
    "    D1 = tf.keras.layers.Dense(np.prod(latent_space_dim))(dense_input)\n",
    "    D1 = tf.keras.layers.BatchNormalization()(D1)\n",
    "    D1 = tf.keras.activations.tanh(D1)\n",
    "\n",
    "    D2 = tf.keras.layers.Dense(1024)(D1)\n",
    "    D2 = tf.keras.layers.BatchNormalization()(D2)\n",
    "    D2 = tf.keras.activations.tanh(D2)\n",
    "\n",
    "    D3 = tf.keras.layers.Dense(512)(D2)\n",
    "    D3 = tf.keras.layers.BatchNormalization()(D3)\n",
    "    D3 = tf.keras.activations.tanh(D3)\n",
    "\n",
    "    D4 = tf.keras.layers.Dense(256)(D3)\n",
    "    D4 = tf.keras.layers.BatchNormalization()(D4)\n",
    "    D4 = tf.keras.activations.tanh(D4)\n",
    "\n",
    "    D5 = tf.keras.layers.Dense(128)(D4)\n",
    "    D5 = tf.keras.layers.BatchNormalization()(D5)\n",
    "    D5 = tf.keras.activations.tanh(D5)\n",
    "\n",
    "    D6 = tf.keras.layers.Dense(64)(D5)\n",
    "    D6 = tf.keras.layers.BatchNormalization()(D6)\n",
    "    D6 = tf.keras.activations.tanh(D6)\n",
    "\n",
    "    D7 = tf.keras.layers.Dense(32)(D6)\n",
    "    D7 = tf.keras.layers.BatchNormalization()(D7)\n",
    "    last = tf.keras.layers.Dense(6)(D7)\n",
    "\n",
    "    return tf.keras.Model(inputs=dense_input, outputs=last, name='latent_decoder')\n",
    "\n",
    "zernike_decoder = latent_decoder(latent_space_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Zernike Decoder Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 10\n",
    "ALPHA = 1\n",
    "\n",
    "loss_object_zernike = tf.keras.losses.MeanAbsoluteError()\n",
    "loss_object_phase = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "def generate_zernike(coef, normalize=True):\n",
    "    Phi = cart.eval_grid(coef, matrix=True)\n",
    "    if normalize:\n",
    "        Phi = normaliza_pos(Phi)\n",
    "    return Phi\n",
    "\n",
    "def zernike2phi(coef):\n",
    "    # Phi = tf.map_fn(generate_zernike, coef)\n",
    "    Phi = tf.map_fn(\n",
    "        lambda x: generate_zernike(x, normalize=False),\n",
    "        coef\n",
    "    )\n",
    "    B = np.nan_to_num(Phi, nan=0)\n",
    "    return B\n",
    "\n",
    "def zernike2cos(coef):\n",
    "    Phi = tf.map_fn(\n",
    "        lambda x: generate_zernike(x, normalize=False),\n",
    "        coef\n",
    "    )\n",
    "    Phi = tf.math.cos(Phi)\n",
    "    B = np.nan_to_num(Phi, nan=0)\n",
    "    return B\n",
    "\n",
    "def zernike2gradient(coef):\n",
    "    Phi = tf.map_fn(\n",
    "        lambda x: generate_zernike(x, normalize=False),\n",
    "        coef\n",
    "    )\n",
    "    Phi = tf.convert_to_tensor(\n",
    "        np.expand_dims(\n",
    "            np.nan_to_num(Phi), \n",
    "            axis=3\n",
    "        )\n",
    "    )\n",
    "    dx, dy = tf.image.image_gradients(Phi)\n",
    "    return dx, dy\n",
    "\n",
    "def cos_loss(y_true, y_pred):\n",
    "    phi = zernike2cos(y_true)\n",
    "    hat_phi = zernike2cos(y_pred)\n",
    "    return LAMBDA * loss_object_phase(phi, hat_phi)\n",
    "\n",
    "def phase_loss(y_true, y_pred):\n",
    "    phi = zernike2phi(y_true)\n",
    "    hat_phi = zernike2phi(y_pred)\n",
    "    return ALPHA * loss_object_phase(phi, hat_phi)\n",
    "\n",
    "def grad_loss(y_true, y_pred):\n",
    "    dx_true, dy_true = zernike2gradient(y_true)\n",
    "    dx_pred, dy_pred = zernike2gradient(y_pred)\n",
    "    return LAMBDA * (0.5*loss_object(dx_true, dx_pred) + 0.5*loss_object(dy_true, dy_pred))\n",
    "    \n",
    "def zernike_loss(y_true, y_pred):\n",
    "    return ALPHA * loss_object_zernike(y_true, y_pred)\n",
    "\n",
    "def total_zernike_loss(y_true, y_pred):\n",
    "    return phase_loss(y_true, y_pred) + grad_loss(y_true, y_pred) + zernike_loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training The Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Optimizers And Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
    "zernike_decoder_optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
    "\n",
    "def generate_images(models, test_input, tar):\n",
    "\n",
    "    encoder = models[0]\n",
    "    decoder = models[1]\n",
    "    zernike_decoder = models[2]\n",
    "\n",
    "    encoded_image = encoder(test_input, training=True)\n",
    "    prediction = decoder(encoded_image, training=True)\n",
    "    zernikes = zernike_decoder(encoded_image, training=True)\n",
    "\n",
    "    generated_zernike = np.nan_to_num(\n",
    "        generate_zernike(zernikes[0].numpy(), normalize=False), \n",
    "        nan=0\n",
    "    )\n",
    "    \n",
    "    got = np.nan_to_num(\n",
    "        generate_zernike(tar[0].numpy(), normalize=False),\n",
    "        nan=0\n",
    "    )\n",
    "    error = np.abs(got - generated_zernike)\n",
    "\n",
    "    plt.figure(figsize=(25,15))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0], generated_zernike, got, error]\n",
    "    title = [\n",
    "        'Input Image', \n",
    "        'Autoencoder', \n",
    "        np.round(zernikes[0].numpy(), decimals=2), \n",
    "        np.round(tar[0].numpy(), decimals=2),\n",
    "        'Phase Error'\n",
    "    ]\n",
    "    \n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.title(title[i])\n",
    "        # Getting the pixel values in the [0, 1] range to plot.\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.colorbar(fraction=0.046)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Autoencoder: Training Step and Fit Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step_ae(input_image):\n",
    "    with tf.GradientTape() as autoencoder_tape:\n",
    "        encoded_image = encoder(input_image, training=True)\n",
    "        decoded_image = decoder(encoded_image, training=True)\n",
    "\n",
    "        autoencoder_loss = ae_loss(input_image, decoded_image)\n",
    "\n",
    "    autoencoder_gradients = autoencoder_tape.gradient(\n",
    "        autoencoder_loss, \n",
    "        encoder.trainable_variables + decoder.trainable_variables\n",
    "    )\n",
    "\n",
    "    autoencoder_optimizer.apply_gradients(zip(\n",
    "        autoencoder_gradients, \n",
    "        encoder.trainable_variables + decoder.trainable_variables\n",
    "    ))\n",
    "    \n",
    "    return autoencoder_loss\n",
    "\n",
    "@tf.function()\n",
    "def validation_step_ae(input_image):\n",
    "    encoded_image = encoder(input_image, training=False)\n",
    "    decoded_image = decoder(encoded_image, training=False)\n",
    "    autoencoder_loss = ae_loss(input_image, decoded_image)\n",
    "    return autoencoder_loss\n",
    "\n",
    "def plot_graphs_ae(record, epoch):\n",
    "    x = range(epoch)\n",
    "    fig, ax1 = plt.subplots(figsize=(10,4))\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('autoencoder_loss')\n",
    "    ax1.plot(x, record['autoencoder_loss'], label='training_loss', color='tab:red')\n",
    "    ax1.plot(x, record['validation_loss'], label='validation_loss', color='tab:blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def fit_ae(train_ds, val_ds, test_ds, epochs):\n",
    "\n",
    "    record = {\n",
    "        'autoencoder_loss': [],\n",
    "        'validation_loss': []\n",
    "    }\n",
    "\n",
    "    example_input, example_target = next(iter(test_ds.take(1)))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "        n = 0\n",
    "        for input_image, target in train_ds:\n",
    "            autoencoder_loss = train_step_ae(input_image)\n",
    "            if n % 10 == 0:\n",
    "                print('.', end='')\n",
    "            n += 1\n",
    "        \n",
    "        for input_image, target in val_ds:\n",
    "            validation_loss = validation_step_ae(input_image)\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        generate_images([encoder, decoder, zernike_decoder], \n",
    "                        example_input, \n",
    "                        example_target)\n",
    "        \n",
    "        record['autoencoder_loss'].append(autoencoder_loss.numpy())\n",
    "        record['validation_loss'].append(validation_loss.numpy())\n",
    "        plot_graphs_ae(record, epoch + 1)\n",
    "\n",
    "        print(\"Time taken: \", time.time() - start)\n",
    "        print(\"Autoencoder Loss: \", autoencoder_loss.numpy())\n",
    "        \n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Autoencoder: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "record = fit_ae(train_ds, val_dataset, test_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Autoencoder: Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = tf.keras.models.Model(\n",
    "    inputs=encoder.inputs, \n",
    "    outputs=decoder(encoder.outputs)\n",
    ")\n",
    "autoencoder.compile(optimizer=autoencoder_optimizer, \n",
    "                    loss=ae_loss)\n",
    "autoencoder.evaluate(X_test_cos, X_test_cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training The Zernike Decoder\n",
    "\n",
    "The encoder model can be trained with the autoencoder or loaded from the saved models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Zernike Decoder: Training Step and Fit Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step_zae(input_image, target):\n",
    "    with tf.GradientTape() as zernike_decoder_tape:\n",
    "        encoded_image = encoder(input_image)\n",
    "        zernikes = zernike_decoder(encoded_image, training=True)\n",
    "\n",
    "        # Loss calculation\n",
    "        zernike_decoder_loss = zernike_loss(target, zernikes)\n",
    "        estimated_phase_loss = phase_loss(target, zernikes)\n",
    "        estimated_grad_loss =  grad_loss(target, zernikes)\n",
    "\n",
    "        # Total loss\n",
    "        total_zernike_decoder_loss = zernike_decoder_loss +\\\n",
    "                                    estimated_phase_loss + \\\n",
    "                                    estimated_grad_loss\n",
    "\n",
    "    zernike_decoder_gradients = zernike_decoder_tape.gradient(\n",
    "        total_zernike_decoder_loss, \n",
    "        zernike_decoder.trainable_variables\n",
    "    )\n",
    "    \n",
    "    zernike_decoder_optimizer.apply_gradients(zip(\n",
    "        zernike_decoder_gradients, \n",
    "        zernike_decoder.trainable_variables\n",
    "    )) \n",
    "\n",
    "    return [zernike_decoder_loss, \n",
    "            estimated_phase_loss, \n",
    "            estimated_grad_loss]\n",
    "\n",
    "def plot_graphs_zae(record, epoch):\n",
    "    x = range(epoch)\n",
    "    fig, ax1 = plt.subplots(figsize=(10,4))\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('total_zernike_decoder_loss', color=color)\n",
    "    ax1.plot(x, record['total_zernike_decoder_loss'], color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('training time', color=color)\n",
    "    ax2.plot(x, record['time'], color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fit_zae(train_ds, test_ds, epochs):\n",
    "    # tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "    record = {\n",
    "        'zernike_decoder_loss': [],\n",
    "        'estimated_phase_loss': [],\n",
    "        'estimated_grad_loss': [],\n",
    "        'total_zernike_decoder_loss': [], \n",
    "        'time': []\n",
    "    }\n",
    "\n",
    "    example_input, example_target = next(iter(test_ds.take(1)))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        print(\"Epoch: \", epoch + 1)\n",
    "\n",
    "        n = 0\n",
    "        for input_image, target in train_ds:\n",
    "            zernike_decoder_loss = train_step_zae(input_image,\n",
    "                                                  target)\n",
    "            if n % 10 == 0:\n",
    "                print('··', end='')\n",
    "            n += 1\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        generate_images([encoder, decoder, zernike_decoder], \n",
    "                        example_input, \n",
    "                        example_target)\n",
    "        \n",
    "        record['zernike_decoder_loss'].append(zernike_decoder_loss[0].numpy())\n",
    "        record['estimated_phase_loss'].append(zernike_decoder_loss[1].numpy())\n",
    "        record['estimated_grad_loss'].append(zernike_decoder_loss[2].numpy())\n",
    "        record['total_zernike_decoder_loss'].append(\n",
    "            zernike_decoder_loss[0].numpy() + \\\n",
    "            zernike_decoder_loss[1].numpy() + \\\n",
    "            zernike_decoder_loss[2].numpy()\n",
    "        )\n",
    "        delta_time = time.time() - start\n",
    "        record['time'].append(delta_time)\n",
    "\n",
    "        plot_graphs_zae(record, epoch + 1)\n",
    "\n",
    "        print(\"Time taken: \", delta_time)\n",
    "        print(\"Zernike Decoder Loss: \", zernike_decoder_loss[0].numpy())\n",
    "        print(\"Estimated Phase Loss: \", zernike_decoder_loss[1].numpy())\n",
    "        print(\"Estimated Gradient Loss: \", zernike_decoder_loss[2].numpy())\n",
    "        print(\"Total Zernike Decoder Loss: \", \n",
    "              zernike_decoder_loss[0].numpy() + \\\n",
    "              zernike_decoder_loss[1].numpy() + \\\n",
    "              zernike_decoder_loss[2].numpy())\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Zernike Decoder: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "np_config.enable_numpy_behavior()\n",
    "tf.config.run_functions_eagerly(True)\n",
    "record = fit_zae(train_ds, test_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Save models and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "with open('../data/record.pkl', 'wb') as f:\n",
    "    pickle.dump(record, f)\n",
    "\n",
    "# zernike_decoder.save('../models/zae_zernike_decoder.h5')\n",
    "# encoder.save('../models/ae_encoder.h5')\n",
    "# decoder.save('../models/ae_decoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Load Trained Models for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(path, optimizer, loss):\n",
    "    model = tf.keras.models.load_model(path, compile=False)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=loss)\n",
    "    return model\n",
    "\n",
    "encoder = model_loader('../models/ae_encoder.h5',\n",
    "                       autoencoder_optimizer,\n",
    "                       ae_loss)\n",
    "decoder = model_loader('../models/ae_decoder.h5',\n",
    "                       autoencoder_optimizer,\n",
    "                       ae_loss)\n",
    "\n",
    "zernike_decoder = model_loader('../models/zae_zernike_decoder.h5',\n",
    "                               zernike_decoder_optimizer,\n",
    "                               total_zernike_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zautoencoder = tf.keras.models.Model(\n",
    "    inputs=encoder.inputs, \n",
    "    outputs=zernike_decoder(encoder.outputs)\n",
    ")\n",
    "zautoencoder.compile(optimizer=zernike_decoder_optimizer, \n",
    "                     loss=total_zernike_loss)\n",
    "zautoencoder.evaluate(X_test_cos, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input, example_target = next(iter(test_dataset.take(5)))\n",
    "zernike_coefs = zautoencoder.predict(example_input)\n",
    "generated_zernike = zernike2phi(zernike_coefs)\n",
    "generated_zernike_cos = zernike2cos(zernike_coefs)\n",
    "real_zernike = zernike2phi(example_target)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 4, 4*i+1)\n",
    "    plt.imshow(example_input[i])\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(5, 4, 4*i+2)\n",
    "    plt.imshow(generated_zernike_cos[i])\n",
    "    plt.title(\"Generated Zernike Cos\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(5, 4, 4*i+3)\n",
    "    plt.imshow(real_zernike[i])\n",
    "    plt.title(\"Real Zernike\")\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.subplot(5, 4, 4*i+4)\n",
    "    plt.imshow(generated_zernike[i])\n",
    "    plt.title(\"Generated Zernike\")\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
